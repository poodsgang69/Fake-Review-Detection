{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "851b1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5521103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e69245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from noice_code.ipynb\n",
      "<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000025F66A0C160>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Amar\n",
      "[nltk_data]     Anikethvarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        7\n",
      "1       24\n",
      "2        5\n",
      "3        6\n",
      "4       11\n",
      "        ..\n",
      "9721    11\n",
      "9722     7\n",
      "9723    10\n",
      "9724     5\n",
      "9725    10\n",
      "Name: matchesDf, Length: 9726, dtype: int64\n",
      "Targus PAUK10U Ultra Mini USB Keypad, Black When least you think so, this product will save the day. Just keep it around just in case you need it for something.\n",
      "7333\n",
      "1467\n",
      "2983\n",
      "Now 2983 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Amar\n",
      "[nltk_data]     Anikethvarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Amar\n",
      "[nltk_data]     Anikethvarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Amar\n",
      "[nltk_data]     Anikethvarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 2983 rawData, 2386 trainData, 597 testData\n",
      "Training Samples: \n",
      "2386\n",
      "Features: \n",
      "80031\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Mean of cross-validations (Accuracy, Precision, Recall, Fscore):  [0.85918004 0.86381842 0.85892089 0.85808078]\n",
      "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]\n",
      "3.7\n",
      "Training Classifier...\n",
      "accuracy:  0.8659966499162479\n",
      "Precision:  0.8658655702700861\n",
      "Recall:  0.8659966499162479\n",
      "f1-score:  0.8647638464152225\n",
      "({'my girlfriend': 1, 'girlfriend avid': 1, 'avid fan': 1, 'fan apple': 1, 'apple product': 1, 'product this': 1, 'this perfect': 1, 'perfect gift': 1, 'gift i': 1, 'i could': 1, 'could give': 1, 'give loved': 1, 'loved is': 1, 'is great': 1, 'great color': 1, 'color perfectly': 1, 'perfectly match': 1, 'match actual': 1, 'actual logo': 1, 'logo io': 1, 'io the': 1, 'the magnet': 1, 'magnet great': 1, 'great stick': 1, 'stick well': 1, 'well fridge': 1, 'my': 1, 'girlfriend': 1, 'avid': 1, 'fan': 1, 'apple': 1, 'product': 1, 'this': 1, 'perfect': 1, 'gift': 1, 'i': 1, 'could': 1, 'give': 1, 'loved': 1, 'is': 1, 'great': 1, 'color': 1, 'perfectly': 1, 'match': 1, 'actual': 1, 'logo': 1, 'io': 1, 'the': 1, 'magnet': 1, 'stick': 1, 'well': 1, 'fridge': 1}, 1)\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0, 1] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import noice_code\n",
    "\n",
    "# # import noice_code\n",
    "# DATA_PATH = \"/content\"\n",
    "# # predictor_pickle = open(DATA_PATH+'/predictor.pickle','rb')\n",
    "# predictor_pickle = open('predictor.pickle','rb')\n",
    "# best_model2 = pickle.load(predictor_pickle)\n",
    "\n",
    "# classifier_pickle = open(DATA_PATH+'/classifier.pickle','rb')\n",
    "classifier_pickle = open('classifier.pickle','rb')\n",
    "\n",
    "# best_model3 = pickle.load(classifier_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1852387",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"holy shit why doesnt this model work im so fucking doine\"\n",
    "sample_rating = '3'\n",
    "xfTestData = []\n",
    "xfTestData.append((noice_code.toFeatureVector('4', 'N', 'PC', noice_code.preProcess(sample_text)),sample_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cdf83dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(Pipeline(steps=[('svc', LinearSVC(C=0.01))]))>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier = noice_code.trainClassifier(noice_code.trainData)\n",
    "\n",
    "predictionX = noice_code.predictLabels(xfTestData, noice_code.classifier)\n",
    "noice_code.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "585b67ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7470b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Amar\n",
      "[nltk_data]     Anikethvarma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b6678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDict = {} # A global dictionary of features\n",
    "\n",
    "def toFeatureVector(Rating, verified_Purchase, product_Category, tokens):\n",
    "    localDict = {}\n",
    "    \n",
    "#Labels\n",
    "\n",
    "    # featureDict[\"L\"] = 1   \n",
    "    # localDict[\"L\"] = labels\n",
    "    featureDict[\"R\"] = 1   \n",
    "    localDict[\"R\"] = Rating\n",
    "\n",
    "\n",
    "#Verified_Purchase\n",
    "  \n",
    "    featureDict[\"VP\"] = 1\n",
    "            \n",
    "    if verified_Purchase == \"N\":\n",
    "        localDict[\"VP\"] = 0\n",
    "    else:\n",
    "        localDict[\"VP\"] = 1\n",
    "\n",
    "#Product_Category\n",
    "\n",
    "    \n",
    "    if product_Category not in featureDict:\n",
    "        featureDict[product_Category] = 1\n",
    "    else:\n",
    "        featureDict[product_Category] = +1\n",
    "            \n",
    "    if product_Category not in localDict:\n",
    "        localDict[product_Category] = 1\n",
    "    else:\n",
    "        localDict[product_Category] = +1\n",
    "            \n",
    "            \n",
    "#Text        \n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in featureDict:\n",
    "            featureDict[token] = 1\n",
    "        else:\n",
    "            featureDict[token] = +1\n",
    "            \n",
    "        if token not in localDict:\n",
    "            localDict[token] = 1\n",
    "        else:\n",
    "            localDict[token] = +1\n",
    "    \n",
    "    return localDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3084bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(text):\n",
    "    # Should return a list of tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens=[]\n",
    "    lemmatized_tokens = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.translate(table)\n",
    "    for w in text.split(\" \"):\n",
    "        if w not in stop_words:\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
    "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a03a7d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"really nice product. it works so well :)\"\n",
    "sample_rating = '1'\n",
    "xfTestData = []\n",
    "xfTestData.append((toFeatureVector('4', 'N', 'PC', preProcess(sample_text)),sample_rating))\n",
    "\n",
    "best_model2(xfTestData, best_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8c065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
